# API Configuration
API_URL=https://your-api.com/transcripts
API_TOKEN=your_api_token_here

# Whisper Configuration
WHISPER_BACKEND=pywhispercpp
# Options: pywhispercpp, openai, faster-whisper

# For pywhispercpp
MODEL_PATH=./models/ggml-base.en.bin

# For openai/faster-whisper
MODEL_NAME=base.en
# Options: tiny.en, base.en, small.en, medium.en, large

LANG=en
N_THREADS=4

# VAD Settings
SAMPLE_RATE=16000
VAD_AGGRESSIVENESS=2
# 0 = least aggressive, 3 = most aggressive
SILENCE_DURATION_MS=1000
MIN_RECORDING_DURATION_MS=500

# Connectivity Settings
CONNECTIVITY_CHECK_INTERVAL=5
SEND_CHECK_INTERVAL=2
REQUEST_TIMEOUT=10
MAX_RETRIES=5

# Directories
TEMP_DIR=./data/temp
OUTPUT_DIR=./data/transcripts
QUEUE_DIR=./data/queue
LOG_DIR=./logs

# Hardware optimizations for Raspberry Pi
# Recommended models by RAM:
# 1-2GB RAM: MODEL_PATH=./models/ggml-tiny.en-q8_0.bin
# 2-4GB RAM: MODEL_PATH=./models/ggml-base.en-q5_0.bin
# 4GB+ RAM: MODEL_PATH=./models/ggml-small.en-q5_0.bin

# For Raspberry Pi 4/5 performance tuning
# N_THREADS=2  # Pi 4
# N_THREADS=4  # Pi 5

# Logging
LOG_LEVEL=INFO
# Options: DEBUG, INFO, WARNING, ERROR